{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Deep Learning Model\n",
    "\n",
    "The purpose of this notebook is to create a simple LSTM (Long Short-term memory) neural network model to be deployed to production. LSTM networks are a specific kind of RNN used in Natural language processing as it has the capability of \"remembering\" past states. There will not be a detailed explanation on how RNN or LSTM works within this notebook, for more details head to my [RNN](https://www.kaggle.com/code/bropen24/recurrent-neural-networks-rnn) or [LSTM](https://www.kaggle.com/code/bropen24/character-lstm-in-pytorch) posts on Kaggle. \n",
    "\n",
    "The focus of this project will not be on fine tuning the parameters, but setting up a model that can be saved properly for deployment. Deployment of the model will be performed in the application named `app.py` located in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 22:33:14.032058: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-10 22:33:16.026665: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-10 22:33:16.026752: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-10 22:33:16.322685: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-10 22:33:16.948720: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-10 22:33:16.950063: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-10 22:33:20.524149: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Load all required tensorflow dependencies for LSTM \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKlearn and other utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expressions and other utils\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading  \n",
    "\n",
    "Let's now load the data and valiate the size. In this case we have a file with typical reviews that will need to be tokenized before applying LSTM to it. We will perform some basic data analysis while processing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reviews_dataset.tsv.zip', header=0, delimiter=\"\\t\", quoting=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Superbly trashy and wondrously unpretentious 80\\'s exploitation, hooray! The pre-credits opening sequences somewhat give the false impression that we\\'re dealing with a serious and harrowing drama, but you need not fear because barely ten minutes later we\\'re up until our necks in nonsensical chainsaw battles, rough fist-fights, lurid dialogs and gratuitous nudity! Bo and Ingrid are two orphaned siblings with an unusually close and even slightly perverted relationship. Can you imagine playfully ripping off the towel that covers your sister\\'s naked body and then stare at her unshaven genitals for several whole minutes? Well, Bo does that to his sister and, judging by her dubbed laughter, she doesn\\'t mind at all. Sick, dude! Anyway, as kids they fled from Russia with their parents, but nasty soldiers brutally slaughtered mommy and daddy. A friendly smuggler took custody over them, however, and even raised and trained Bo and Ingrid into expert smugglers. When the actual plot lifts off, 20 years later, they\\'re facing their ultimate quest as the mythical and incredibly valuable White Fire diamond is coincidentally found in a mine. Very few things in life ever made as little sense as the plot and narrative structure of \\\\\"White Fire\\\\\", but it sure is a lot of fun to watch. Most of the time you have no clue who\\'s beating up who or for what cause (and I bet the actors understood even less) but whatever! The violence is magnificently grotesque and every single plot twist is pleasingly retarded. The script goes totally bonkers beyond repair when suddenly \\x96 and I won\\'t reveal for what reason \\x96 Bo needs a replacement for Ingrid and Fred Williamson enters the scene with a big cigar in his mouth and his sleazy black fingers all over the local prostitutes. Bo\\'s principal opponent is an Italian chick with big breasts but a hideous accent, the preposterous but catchy theme song plays at least a dozen times throughout the film, there\\'s the obligatory \\\\\"we\\'re-falling-in-love\\\\\" montage and loads of other attractions! My God, what a brilliant experience. The original French title translates itself as \\\\\"Life to Survive\\\\\", which is uniquely appropriate because it makes just as much sense as the rest of the movie: None!\"'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate that the sentiment 1 means a good review\n",
    "df.loc[4, 'review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dispose the ID column and keep the sentiment and review columns, which are what we will focus on. As we can see from the previous cells, there are only two possible sentiment values, expressed as 0 or 1 expressing a **Negative** and **Positive** review respectively.\n",
    "\n",
    "#### Class balance\n",
    "\n",
    "As part of our process, we need to validate if the data is fairly balanced, if not, some adjustments would need to be made not to favor one of the sentiments over the other while training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          1  \"With all this stuff going down at the moment ...\n",
       "1          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3          0  \"It must be assumed that those who praised thi...\n",
       "4          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the shape, in other words, the size of the DF we will be dealing with\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    12500\n",
       "0    12500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out if we have a balanced DF\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleanup  \n",
    "\n",
    "We now need to start cleaning up the data, for this we will be turning everything to lowercase and then apply a simple regular expression to remove all non-digit, non-alpha and non-white characters from the review text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(lambda x: x.lower())\n",
    "df['review'] = df['review'].apply((lambda x: re.sub('[^a-zA-Z0-9\\s]','',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>with all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the classic war of the worlds by timothy hines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>the film starts with a manager nicholas bell g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>it must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          1  with all this stuff going down at the moment w...\n",
       "1          1  the classic war of the worlds by timothy hines...\n",
       "2          0  the film starts with a manager nicholas bell g...\n",
       "3          0  it must be assumed that those who praised this...\n",
       "4          1  superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'superbly trashy and wondrously unpretentious 80s exploitation hooray the precredits opening sequences somewhat give the false impression that were dealing with a serious and harrowing drama but you need not fear because barely ten minutes later were up until our necks in nonsensical chainsaw battles rough fistfights lurid dialogs and gratuitous nudity bo and ingrid are two orphaned siblings with an unusually close and even slightly perverted relationship can you imagine playfully ripping off the towel that covers your sisters naked body and then stare at her unshaven genitals for several whole minutes well bo does that to his sister and judging by her dubbed laughter she doesnt mind at all sick dude anyway as kids they fled from russia with their parents but nasty soldiers brutally slaughtered mommy and daddy a friendly smuggler took custody over them however and even raised and trained bo and ingrid into expert smugglers when the actual plot lifts off 20 years later theyre facing their ultimate quest as the mythical and incredibly valuable white fire diamond is coincidentally found in a mine very few things in life ever made as little sense as the plot and narrative structure of white fire but it sure is a lot of fun to watch most of the time you have no clue whos beating up who or for what cause and i bet the actors understood even less but whatever the violence is magnificently grotesque and every single plot twist is pleasingly retarded the script goes totally bonkers beyond repair when suddenly  and i wont reveal for what reason  bo needs a replacement for ingrid and fred williamson enters the scene with a big cigar in his mouth and his sleazy black fingers all over the local prostitutes bos principal opponent is an italian chick with big breasts but a hideous accent the preposterous but catchy theme song plays at least a dozen times throughout the film theres the obligatory werefallinginlove montage and loads of other attractions my god what a brilliant experience the original french title translates itself as life to survive which is uniquely appropriate because it makes just as much sense as the rest of the movie none'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[4, 'review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly see the difference in the fourth review, from the first time we looked at the cell ([10]) to the last([19]). The review is clean from punctuation marks and other non-value-adding characters. We now have the text in a format we can tokenize.\n",
    "\n",
    "#### Tokenizing\n",
    "\n",
    "Before we start tokenizing the reviews, we will limit them to the top thousand words found in the \"corpus\" of the reviews, by limiting the number of features. To do this we will be passing the argument `num_words` to the `fit_on_text()` method of the tokenizer instance.\n",
    "\n",
    "Then we will be adding some padding to them, that means that all sentences will become of the same size, that of the longest one.\n",
    "\n",
    "For more information on how [Tokenizer](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer) works, follow the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 1000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(df['review'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(df['review'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1473)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the length of the longest sequence by checking at the shape of the resulting np.array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding layer\n",
    "\n",
    "Embedding layers are used in Natural Language Processing task as an alternative to one-hot-encoding (and dimensional reduction) to be able to train our own word embeddings instead of using pre-trained word embeddings. \n",
    "\n",
    "Once we have our model tokenized, we have a vector of, in our case, a thousand items. This makes the model too cumbersome, so we apply an embedding layer to create a vector dense of fixed size to make it more manageable. This layer works as a kind of lookup table, where words are the keys for the values in the dense vector.\n",
    "\n",
    "To apply the Embedding layer into our model, we define the layer size and pass it as the first step of the model. The model will then be responsible to train this layer to the adequate models by means of the loss and optimization strategies defined for it. We will be defining the Embedding layer by using `Embedding(input_dim, output_dim, input_length)`, for more information on [Embedding](https://keras.io/api/layers/core_layers/embedding/) follow the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 50  # Embedding layer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model sequential model setup using tensorflow\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim, input_length=X.shape[1])) # input_length is given by the size of the input vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Layer\n",
    "\n",
    "As we defined the model to be sequential, we will add a [LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM#attributes) layer to the model with an output size of 10 by passing the argument `LSTM(10)` to `model.add()`.\n",
    "\n",
    "#### Dense layer\n",
    "\n",
    "We will now define the final or output layer of our model by setting up a [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer with 2 outputs (corresponding to the positive and negative sentiments). The activation function to use will be softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add LSTM to the sequential model and a couple of dense layers with a softmax activation function\n",
    "model.add(LSTM(10))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer for model training\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1473, 50)          50000     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 10)                2440      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52462 (204.93 KB)\n",
      "Trainable params: 52462 (204.93 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup y\n",
    "\n",
    "Now we need to setup y as a boolean array matching the two possible sentiment values of a review. To do this, we will use `.get_dummies()`, that produces a one-hotencoding of the sentiment values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup y\n",
    "y = pd.get_dummies(df['sentiment']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-train size:(18750, 1473), y-train size:(18750, 2)\n",
      "X-test size:(6250, 1473), y-test size:(6250, 2)\n"
     ]
    }
   ],
   "source": [
    "# Check the sizes of the resulting splits\n",
    "print('X-train size:{}, y-train size:{}'.format(X_train.shape,y_train.shape))\n",
    "print('X-test size:{}, y-test size:{}'.format(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training\n",
    "\n",
    "After training we get a pretty decent accuracy score of around 87%, we can move forward to saving the model without trying to improve the accuracy (at least for the moment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 22:58:20.746605: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 110475000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "586/586 [==============================] - 172s 290ms/step - loss: 0.4688 - accuracy: 0.7737\n",
      "Epoch 2/5\n",
      "586/586 [==============================] - 167s 285ms/step - loss: 0.3541 - accuracy: 0.8511\n",
      "Epoch 3/5\n",
      "586/586 [==============================] - 168s 286ms/step - loss: 0.3263 - accuracy: 0.8652\n",
      "Epoch 4/5\n",
      "586/586 [==============================] - 168s 286ms/step - loss: 0.3142 - accuracy: 0.8705\n",
      "Epoch 5/5\n",
      "586/586 [==============================] - 171s 292ms/step - loss: 0.2999 - accuracy: 0.8763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f85d251fd30>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model\n",
    "\n",
    "To test the model we will create a sample review and peform all the data setup processes we performed with the dataframe reviews. This way the data will be encoded in a similar way.\n",
    "\n",
    "We will define a definite negative review to test the model, we will get the correct sentiment from the prediction, as we can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1473)\n"
     ]
    }
   ],
   "source": [
    "test = ['Movie was pathetic'] # Negative review\n",
    "test = tokenizer.texts_to_sequences(test)\n",
    "test = pad_sequences(test, maxlen=X.shape[1], dtype='int32', value=0) # Add padding\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 324ms/step\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "sentiment = model.predict(test)[0]\n",
    "if(np.argmax(sentiment)==0):\n",
    "    print('Negative')\n",
    "elif(np.argmax(sentiment)==1):\n",
    "    print('Positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model for deployment\n",
    "\n",
    "Now we will save the model and tokenizer steps in pickle format for deployment into production. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle dump the tokenizer step\n",
    "with open('tokenizer.pickle', 'wb') as tk:\n",
    "    pickle.dump(tokenizer, tk, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model as json\n",
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as js:\n",
    "    js.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5') # Save model weights in hierarchical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
